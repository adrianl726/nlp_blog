<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Adrian Leung">
<meta name="dcterms.date" content="2025-01-17">

<title>A Guide to Encoding Texts for Natural Language Processing – Adrian Leung’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Adrian Leung’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A Guide to Encoding Texts for Natural Language Processing</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">tutorial</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Adrian Leung </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 17, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="thumbnail.png" class="img-fluid figure-img"></p>
<figcaption>Source: Google</figcaption>
</figure>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Natural Language Processing (NLP) is a fascinating field of Machine Learning that focuses on enabling machines to understand, interpret, and generate human language. From facilitating translation tools like Google Translate to powering voice assistance like Siri and Alexa, NLP’s influence on the current technological landscape is indisputable and substantial. With the ever-growing interest and expanding development in artificial intelligence, a lot of aspiring engineers and scientists are looking to venture into the lucrative NLP field. However, before we learn to perform all the fancy tasks such as text generation and summarization, we must start from the fundamentals and ask ourselves a question:</p>
<p><strong>How can we bridge the gap between human communication and machine processing?</strong></p>
<p>One problem that arises from this question is that computers do not understand language the way humans do. They are not wired to comprehend words and write essays like we do. Instead, they operate on numbers. All the NLP models are driven by mathematical algorithms and formulae. Thus, encoding text into numerical representations becomes the key to computers learning human language. By converting words, sentences, or entire documents into numbers, NLP models can perform a wide range of tasks like analyzing patterns, extracting meanings, and generating responses.</p>
<p>This blog will introduce and guide you through different methods and tools to encode texts, thus providing you with a gateway to performing NLP tasks.</p>
</section>
<section id="challenges-of-textual-data" class="level2">
<h2 class="anchored" data-anchor-id="challenges-of-textual-data">Challenges of Textual Data</h2>
<p>Before we learn about different ways to encode texts, we need to acknowledge the challenges associated with the intricacy of human language. Language is messy and unpredictable. Although there are sets of grammatical rules that govern a language, humans are prone to making mistakes yet still able to convey their messages. For example, “How is you doin” is grammatically incorrect but we know it means “How are you doing”. Thus, language is not strictly restricted by an algorithm, contrary to how computers operate.</p>
<p>Moreover, not all words have meanings. Auxiliary verbs like “is” and “am” do not contribute to or change the message a sentence wants to convey. They are meaningless outside of abiding by grammatical rules. There is also a hierarchy of meanings in a sentence. Certain words can mean more than others. Consider the sentence “We are happy”. Although “we” and “happy” play their roles in conveying our emotions, “happy” is a more important word as it tells the key emotion.</p>
<p>To complicate matters more, a word can have different meanings depending on the context. Even more confusingly, some words can have completely opposite meanings. For example, the word “left” in the sentence “We just left” means departed. However, it means staying when the sentence is “We are the only one left”. This shows that contexts can alter the meanings of the same word drastically.</p>
<div style="text-align:center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="context.gif" class="img-fluid figure-img"></p>
<figcaption>Context matters!!! (Source: Kamala Harris)</figcaption>
</figure>
</div>
</div>
<p>Hence, making computers comprehend language like we do is far from a simple task. Encoding words with numerical representations is a work of art as it determines how well a model can understand us.</p>
<p>The sections below will cover different approaches to encoding texts including traditional methods like Bag-of-Words (BoW) and TF-IDF, word embeddings, and contextualized embeddings.</p>
</section>
<section id="traditional-methods" class="level2">
<h2 class="anchored" data-anchor-id="traditional-methods">Traditional Methods</h2>
<section id="bag-of-words-bow" class="level3">
<h3 class="anchored" data-anchor-id="bag-of-words-bow">Bag-of-Words (BoW)</h3>
<p>BoW is one of the most popular encoding methods. It encodes each unique word from all input documents with a number based on their count or presence in their respective document.</p>
<p>Consider the example below:</p>
<p>Unique words in all documents: <strong>[‘the’, ‘bird’, ‘is’, ‘cat’, ‘and’, ‘dog’, ‘hate’, ‘each’, ‘no’, ‘other’]</strong></p>
<p>And we pick one of the documents for our first BoW representation as below.</p>
<p>Document: <strong>“The cat and the cat hate each other.”</strong></p>
<p>In the case of encoding each word with its count, the BoW model will transform the document to the representation in <a href="#tbl-boWcount" class="quarto-xref">Table&nbsp;1</a>. Since we have two ‘the’ and ‘cat’ in the document above, the numerical representations for ‘the’ and ‘cat’ in this document are 2.</p>
<div id="tbl-boWcount" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-boWcount-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">the</th>
<th style="text-align: center;">bird</th>
<th style="text-align: center;">is</th>
<th style="text-align: center;">cat</th>
<th style="text-align: center;">and</th>
<th style="text-align: center;">dog</th>
<th style="text-align: center;">hate</th>
<th style="text-align: center;">each</th>
<th style="text-align: center;">no</th>
<th style="text-align: center;">other</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-boWcount-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: BoW representations using word counts
</figcaption>
</figure>
</div>
<p>In the case of measuring each word by its presence as seen in <a href="#tbl-boWbinary" class="quarto-xref">Table&nbsp;2</a>, BoW uses binary values 0 and 1 to represent each word, where 0 implies absence and 1 implies presence. Note that the words ‘the’ and ‘cat’ are represented by 1 instead of 2 since we are using binary representations.</p>
<div id="tbl-boWbinary" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-boWbinary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">the</th>
<th style="text-align: center;">bird</th>
<th style="text-align: center;">is</th>
<th style="text-align: center;">cat</th>
<th style="text-align: center;">and</th>
<th style="text-align: center;">dog</th>
<th style="text-align: center;">hate</th>
<th style="text-align: center;">each</th>
<th style="text-align: center;">no</th>
<th style="text-align: center;">other</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-boWbinary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: BoW representations using binary indicators
</figcaption>
</figure>
</div>
<p>To extract BoW representations in Python <span class="citation" data-cites="van1995python">[<a href="#ref-van1995python" role="doc-biblioref">1</a>]</span>, we can leverage the <code>CountVectorizer</code> function from the <code>scikit-learn</code> package <span class="citation" data-cites="scikit-learn">[<a href="#ref-scikit-learn" role="doc-biblioref">2</a>]</span>. <a href="#tbl-sklearn" class="quarto-xref">Table&nbsp;3</a> demonstrates using <code>CountVectorizer</code> for BoW extraction by word count with the same example.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Using above example</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>documents <span class="op">=</span> [</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'The cat and the cat hate each other.'</span>,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'The dog is the bird.'</span>,</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'No, the bird and cat hate other dog.'</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>bow <span class="op">=</span> CountVectorizer()</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> bow.fit_transform(documents)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>bow_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    X.toarray(), columns<span class="op">=</span>bow.get_feature_names_out(), index<span class="op">=</span>documents</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>bow_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="tbl-sklearn" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="1">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-sklearn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe do-not-create-environment cell table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">and</th>
<th data-quarto-table-cell-role="th">bird</th>
<th data-quarto-table-cell-role="th">cat</th>
<th data-quarto-table-cell-role="th">dog</th>
<th data-quarto-table-cell-role="th">each</th>
<th data-quarto-table-cell-role="th">hate</th>
<th data-quarto-table-cell-role="th">is</th>
<th data-quarto-table-cell-role="th">no</th>
<th data-quarto-table-cell-role="th">other</th>
<th data-quarto-table-cell-role="th">the</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">The cat and the cat hate each other.</td>
<td>1</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">The dog is the bird.</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">No, the bird and cat hate other dog.</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-sklearn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: BoW results from CountVectorizer
</figcaption>
</figure>
</div>
</div>
<p>Although the BoW method is as intuitive and self-explanatory as it seems, it is far from a perfect model as it discards the word order in the original document. It disregards how words can form meaningful word phrases and change their meanings with respect to the context.</p>
</section>
<section id="tf-idf" class="level3">
<h3 class="anchored" data-anchor-id="tf-idf">TF-IDF</h3>
<p>TF-IDF, which stands for term frequency-inverse document frequency, is another popular method to encode text. It is a measure of the relevance of a word in a document. The computation can be broken down into two parts: term frequency and inverse document frequency.</p>
<p><strong>Term Frequency (TF)</strong><br>
The term frequency is the count of a given word <span class="math inline">\(w\)</span> in a given document <span class="math inline">\(d\)</span>, divided by the total number of words in document <span class="math inline">\(d\)</span>.</p>
<p><span class="math display">\[TF = \frac{\text{Number of word $w$ in document $d$}}{\text{Total number of words in document $d$}}\]</span></p>
<p><strong>Inverse document frequency (IDF)</strong><br>
The inverse document frequency is to penalize words that are too common across all documents. For example, auxiliary verbs like ‘is’ are weighed less as a result. In return, this gives rise to rarer words that possibly carry more meaning and importance.</p>
<p><span class="math display">\[IDF = \log\left(\frac{\text{Total number of documents}}{\text{Number of documents containing word $w$}}\right)\]</span></p>
<p><strong>Combining both TF and IDF</strong><br>
To have our TF-IDF representation, we multiply both terms to have the following formula:</p>
<p><span class="math display">\[TF\text{-}IDF = TF \times IDF\]</span></p>
<p>Now, let’s revisit our example with TF-IDF in Python. Luckily, the <code>scikit-learn</code> package <span class="citation" data-cites="scikit-learn">[<a href="#ref-scikit-learn" role="doc-biblioref">2</a>]</span> also has a function for TF-IDF called <code>TfidfVectorizer</code>. As shown in the first row in <a href="#tbl-tfidf" class="quarto-xref">Table&nbsp;4</a>, the TF-IDF representation for ‘the’ is smaller than ‘cat’ even though they both have the same BoW representations in <a href="#tbl-sklearn" class="quarto-xref">Table&nbsp;3</a>. This is the result of the compensation from IDF as ‘the’ is too common among existing documents.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Using the same example</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>documents <span class="op">=</span> [</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'The cat and the cat hate each other.'</span>,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'The dog is the bird.'</span>,</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'No, the bird and cat hate other dog.'</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>tfidf <span class="op">=</span> TfidfVectorizer()</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> tfidf.fit_transform(documents)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>tfidf_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    X.toarray(), columns<span class="op">=</span>tfidf.get_feature_names_out().tolist(), index<span class="op">=</span>documents</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>tfidf_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="tbl-tfidf" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="2">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-tfidf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe do-not-create-environment cell table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">and</th>
<th data-quarto-table-cell-role="th">bird</th>
<th data-quarto-table-cell-role="th">cat</th>
<th data-quarto-table-cell-role="th">dog</th>
<th data-quarto-table-cell-role="th">each</th>
<th data-quarto-table-cell-role="th">hate</th>
<th data-quarto-table-cell-role="th">is</th>
<th data-quarto-table-cell-role="th">no</th>
<th data-quarto-table-cell-role="th">other</th>
<th data-quarto-table-cell-role="th">the</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">The cat and the cat hate each other.</td>
<td>0.299594</td>
<td>0.000000</td>
<td>0.599187</td>
<td>0.000000</td>
<td>0.39393</td>
<td>0.299594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.299594</td>
<td>0.465322</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">The dog is the bird.</td>
<td>0.000000</td>
<td>0.403525</td>
<td>0.000000</td>
<td>0.403525</td>
<td>0.00000</td>
<td>0.000000</td>
<td>0.530587</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.626747</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">No, the bird and cat hate other dog.</td>
<td>0.346438</td>
<td>0.346438</td>
<td>0.346438</td>
<td>0.346438</td>
<td>0.00000</td>
<td>0.346438</td>
<td>0.000000</td>
<td>0.455524</td>
<td>0.346438</td>
<td>0.269040</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-tfidf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: TF-IDF results from TfidfVectorizer
</figcaption>
</figure>
</div>
</div>
<p>TF-IDF is a step up from BoW as it recognizes what makes a word important in a document. However, similar to BoW, it also disregards the order and context of words. Thus, we need some alternatives that can compute an even better representation for words.</p>
</section>
</section>
<section id="word-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="word-embeddings">Word Embeddings</h2>
<p>This is where word embeddings come into play. Contrary to traditional methods, word embeddings encode words in vector forms (from Linear Algebra!). Through vector representations, they can encapsulate the relationships between words by showing their similarity numerically. Mathematically, the similarity in words is measured by how close the embeddings are in the vector space. <a href="#fig-embedding" class="quarto-xref">Figure&nbsp;1</a> shows an example of visualizing word embeddings in a 2-dimensional space. As you can see, words that are similar in meaning or context are clustered together. This is the art of word embeddings!</p>
<div id="fig-embedding" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-embedding-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="wordembedding.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-embedding-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Visualization of word embeddings (Source: Ruben Winastwan)
</figcaption>
</figure>
</div>
<section id="word2vec" class="level3">
<h3 class="anchored" data-anchor-id="word2vec">Word2Vec</h3>
<p>One common tool to obtain word embeddings is Word2Vec <span class="citation" data-cites="mikolov2013efficient">[<a href="#ref-mikolov2013efficient" role="doc-biblioref">3</a>]</span>. It computes the embeddings by leveraging the architecture of two-layer neural networks. There are two approaches that Word2Vec uses to obtain these embeddings.</p>
<p><strong>Continuous BoW (CBoW)</strong></p>
<p>CBoW is a prediction algorithm where the neural network aims to predict a target word based on the existing context in a document. Simply put, this is analogous to filling in the blank in a sentence.</p>
<p>Consider the sentence <em>“My cute puppy is barking”</em>. The model will iterate over this sentence and remove one word from each iteration. For example, as shown in <a href="#fig-cbow" class="quarto-xref">Figure&nbsp;2</a>, the model omits the word <em>‘puppy’</em> from the sentence and trains the neural network to guess the word <em>‘puppy’</em> from the remaining sentence.</p>
<div style="text-align:center;">
<div id="fig-cbow" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cbow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="cbow.jpeg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cbow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Illustration of CBoW algorithm
</figcaption>
</figure>
</div>
</div>
<p><strong>Skipgram</strong></p>
<p>Skipgram is the complete opposite of CBoW. Instead of predicting the missing word from a given context, skipgram predicts the surrounding context from a given word. Using the same example, as shown in <a href="#fig-skipgram" class="quarto-xref">Figure&nbsp;3</a>, the model will try to guess the surrounding words to the word <em>‘puppy’</em>.</p>
<div style="text-align:center;">
<div id="fig-skipgram" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-skipgram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="skipgram.jpeg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-skipgram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Illustration of Skipgram algorithm
</figcaption>
</figure>
</div>
</div>
<p>After multiple iterations in the training process, Word2Vec will use the learned weights in the neural network from either of the approaches to construct the word embeddings for each word.</p>
<p>Applying Word2Vec in Python is made possible with the package <code>Gensim</code> <span class="citation" data-cites="rehurek2011gensim">[<a href="#ref-rehurek2011gensim" role="doc-biblioref">4</a>]</span>. As seen in <a href="#lst-gensim" class="quarto-xref">Listing&nbsp;1</a>, <code>Gensim</code>‘s <code>Word2Vec</code> takes in a list of lists to generate the word embeddings. Note that the <code>sg</code> argument in the function lets you choose between CBoW and skipgram, where 0 and 1 correspond to CBoW and skipgram respectively. The argument <code>min_count</code> tells the model to ignore words that have a lower count than this minimum. After training <code>Word2Vec</code> on our sample text, we can take a quick look into what word embeddings look like for the word ’technology’ in <a href="#lst-gensim" class="quarto-xref">Listing&nbsp;1</a>.</p>
<div id="91d8aa50" class="cell" data-execution_count="3">
<div id="lst-gensim" class="python cell-code listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-gensim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;1: This code demonstrates extracting word embedding from the word ‘technology’
</figcaption>
<div aria-describedby="lst-gensim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode cell-code" id="lst-gensim"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst-gensim-1"><a href="#lst-gensim-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="lst-gensim-2"><a href="#lst-gensim-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> Word2Vec</span>
<span id="lst-gensim-3"><a href="#lst-gensim-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Generated by ChatGPT</span></span>
<span id="lst-gensim-4"><a href="#lst-gensim-4" aria-hidden="true" tabindex="-1"></a>sample_text <span class="op">=</span> [</span>
<span id="lst-gensim-5"><a href="#lst-gensim-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The advancement of technology has transformed the way we communicate and interact with the world."</span>,</span>
<span id="lst-gensim-6"><a href="#lst-gensim-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Artificial intelligence is increasingly being used in healthcare, education, and other industries to enhance efficiency."</span>,</span>
<span id="lst-gensim-7"><a href="#lst-gensim-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"People often gather in coffee shops to discuss ideas, share stories, and enjoy a sense of community."</span>,</span>
<span id="lst-gensim-8"><a href="#lst-gensim-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Self-driving cars and smart home devices are examples of how technology is becoming a part of our everyday lives."</span>,</span>
<span id="lst-gensim-9"><a href="#lst-gensim-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Art galleries and cultural festivals are popular spots for people to explore creativity and connect with others."</span>,</span>
<span id="lst-gensim-10"><a href="#lst-gensim-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The integration of AI in the workplace has sparked debates about its impact on jobs and productivity."</span>,</span>
<span id="lst-gensim-11"><a href="#lst-gensim-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Reading books and attending literary events remain cherished activities in the digital age."</span>,</span>
<span id="lst-gensim-12"><a href="#lst-gensim-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Many cities are blending technology with traditional practices to create unique and thriving environments."</span>,</span>
<span id="lst-gensim-13"><a href="#lst-gensim-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The use of virtual reality in gaming and training has opened new possibilities for immersive experiences."</span>,</span>
<span id="lst-gensim-14"><a href="#lst-gensim-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Social media platforms have changed the way we form relationships and share information globally."</span></span>
<span id="lst-gensim-15"><a href="#lst-gensim-15" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="lst-gensim-16"><a href="#lst-gensim-16" aria-hidden="true" tabindex="-1"></a><span class="co"># This generates a list of lists</span></span>
<span id="lst-gensim-17"><a href="#lst-gensim-17" aria-hidden="true" tabindex="-1"></a>sample_sentences <span class="op">=</span> [sent.split() <span class="cf">for</span> sent <span class="kw">in</span> sample_text]</span>
<span id="lst-gensim-18"><a href="#lst-gensim-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-gensim-19"><a href="#lst-gensim-19" aria-hidden="true" tabindex="-1"></a>w2v <span class="op">=</span> Word2Vec(sample_sentences, min_count <span class="op">=</span> <span class="dv">1</span>, sg <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="lst-gensim-20"><a href="#lst-gensim-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(w2v.wv[<span class="st">'technology'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[ 8.1346482e-03 -4.3696621e-03 -1.0951435e-03  1.0827162e-03
 -1.6076697e-04  1.0314664e-03  6.1621480e-03  1.0513653e-04
 -3.3200562e-03 -1.6226495e-03  5.8745840e-03  1.3788766e-03
 -6.8573974e-04  9.4051417e-03 -4.8837205e-03 -9.1557507e-04
  9.1908397e-03  6.7008133e-03  1.4975395e-03 -9.0892995e-03
  1.2369623e-03 -2.2766890e-03  9.4154952e-03  1.1043868e-03
  1.5170779e-03  2.3703994e-03 -1.9285623e-03 -4.9641491e-03
  1.0452364e-04 -2.0255600e-03  6.6222828e-03  8.9008864e-03
 -5.9560389e-04  2.8281522e-03 -6.1490987e-03  1.7546985e-03
 -6.8589435e-03 -8.6309118e-03 -5.9207552e-03 -9.0170074e-03
  7.2529181e-03 -5.8431132e-03  8.1692915e-03 -7.1991798e-03
  3.4998127e-03  9.6219182e-03 -7.8216838e-03 -9.9756923e-03
 -4.2250603e-03 -2.6117193e-03 -2.6378274e-04 -8.8602239e-03
 -8.5995235e-03  2.7603817e-03 -8.2284901e-03 -9.0225162e-03
 -2.3512202e-03 -8.6695738e-03 -7.1790209e-03 -8.3399629e-03
 -2.7452479e-04 -4.5728176e-03  6.6562551e-03  1.5371529e-03
 -3.3772779e-03  6.1904443e-03 -5.9688864e-03 -4.5542065e-03
 -7.3182448e-03 -4.1977805e-03 -1.7964148e-03  6.5716160e-03
 -2.7138642e-03  4.9592862e-03  6.9808913e-03 -7.4309111e-03
  4.5860992e-03  6.1515258e-03 -2.9300000e-03  6.6001783e-03
  6.0655614e-03 -6.4467844e-03 -6.8669897e-03  2.5851957e-03
 -1.7241427e-03 -6.1018453e-03  9.5864786e-03 -5.1106275e-03
 -6.4399107e-03 -4.0861694e-05 -2.5958647e-03  5.0307182e-04
 -3.4884498e-03 -3.8938067e-04 -6.8298483e-04  8.8520558e-04
  8.1980843e-03 -5.7321084e-03 -1.6760164e-03  5.5565243e-03]</code></pre>
</div>
</div>
<p>As it turns out, the word embedding for ‘technology’ is a high-dimensional vector. However, the values are much more ambiguous than the previous representations we have learned earlier. Let’s try to translate these embeddings into more comprehensible results.</p>
<p>As mentioned before, word embeddings are powerful at capturing similarities in words. We are putting this to the test in <a href="#lst-similarity" class="quarto-xref">Listing&nbsp;2</a>, where we ask <code>Word2Vec</code> what the most similar word to ‘technology’ is. The result shows that ‘advancement’ is the closest word choice. This is a reasonable pick since we often use the phrase ‘technological advancement’ when describing new technological milestones.</p>
<div id="dfc303bc" class="cell" data-execution_count="4">
<div id="lst-similarity" class="python cell-code listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-similarity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;2: This code shows what Word2Vec thinks the most similar word to ‘technology’ is.
</figcaption>
<div aria-describedby="lst-similarity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode cell-code" id="lst-similarity"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst-similarity-1"><a href="#lst-similarity-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(w2v.wv.most_similar(<span class="st">'technology'</span>)[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>('advancement', 0.3503554165363312)</code></pre>
</div>
</div>
<p>Word2Vec is a big improvement from traditional methods. Nevertheless, it still has flaws such as failing to recognize unknown words. Since Word2Vec is a pre-trained model, its linguistic knowledge is mainly based on the data corpus it was trained on. Unfortunately, language changes over time as new words continue to pop up in dictionaries every year. Thus, it is only a matter of time before Word2Vec becomes outdated. Another limitation of Word2Vec is its struggle to differentiate between words with multiple meanings. Since Word2Vec generates a word embedding for each unique word, it fails to acknowledge that a word can carry separate meanings. This can be problematic especially when words can have exact opposite meanings given different contexts.</p>
</section>
</section>
<section id="contextualized-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="contextualized-embeddings">Contextualized Embeddings</h2>
<p>Similar to word embeddings, contextualized embeddings also encode texts into high-dimensional vectors. They refine the existing framework of word embeddings by conditioning each word on its context. When obtaining the contextualized embeddings of a word, it includes neighboring words in the calculation. As such, the same words that appear in different contexts will have different embeddings. This provides a solution to the limitations of word embeddings as it learns the word based on the context surrounding it.</p>
<p>While there are several architectures, such as ELMo and GPT-2, that are trained on obtaining contextualized embeddings, we will be focusing on learning the BERT model in this section.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="bertsesame.jpeg" class="img-fluid figure-img"></p>
<figcaption>Bert from Sesame Street. Coincidentally, the popular contextualized embeddings are conveniently named as Sesame Street characters (Source: Sesame Street)</figcaption>
</figure>
</div>
<section id="bert" class="level3">
<h3 class="anchored" data-anchor-id="bert">BERT</h3>
<p>BERT <span class="citation" data-cites="devlin2019bertpretrainingdeepbidirectional">[<a href="#ref-devlin2019bertpretrainingdeepbidirectional" role="doc-biblioref">5</a>]</span>, which stands for Bidirectional encoder representations from transformers, is a transformer-based encoder model developed in 2018 by researchers at Google <span class="citation" data-cites="Devlin_Chang_2018">[<a href="#ref-Devlin_Chang_2018" role="doc-biblioref">6</a>]</span>.</p>
<p>It is bidirectional in the sense that it captures both the left and right contexts of a given word. For example, consider the sentence <em>“You exist in the context of all in which you live”</em> and the target word <em>“context”</em>. The bidirectional nature of BERT ensures that both the left context, <em>“You exist in the”</em>, and the right context, <em>“of all in which you live”</em>, are taken into account.</p>
<p>Transformer <span class="citation" data-cites="vaswani2017attention">[<a href="#ref-vaswani2017attention" role="doc-biblioref">7</a>]</span>, in this context, is a deep-learning architecture that revolutionalizes the field of NLP through its emphasis on contextualized representations. Its usage ranges from language translations to text generations. As shown in <a href="#fig-transformer" class="quarto-xref">Figure&nbsp;4</a>, a transformer is powered by two separate mechanisms: an encoder system that reads an input text and produces a corresponding vector representation, and a decoder system that receives the vector representation and output sentences that are useful in tasks like text generation <span class="citation" data-cites="Hoque_2024">[<a href="#ref-Hoque_2024" role="doc-biblioref">8</a>]</span>. Despite BERT being a transformer-based model, it differs from a typical transformer as BERT only leverages the encoder mechanism of transformers since its goal is to create contextualized embeddings.</p>
<div id="fig-transformer" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-transformer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformer.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-transformer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: An oversimplified visualization of the encoder-decoder mechanism of a transformer. (Source: KiKaBeN)
</figcaption>
</figure>
</div>
<p>To implement BERT in Python, we enlist the help of the Hugging Face library <span class="citation" data-cites="wolf2020huggingfacestransformersstateoftheartnatural">[<a href="#ref-wolf2020huggingfacestransformersstateoftheartnatural" role="doc-biblioref">9</a>]</span>. This implementation requires the packages <code>transformers</code> and <code>torch</code>. To install both packages, use the commands <code>pip install transformers</code> and <code>pip install torch</code> respectively.</p>
<p>Before producing BERT embeddings, we have to tokenize the input text with <code>BertTokenizer</code> in <a href="#lst-token" class="quarto-xref">Listing&nbsp;3</a>. Tokenization is a process where we break down a text into smaller chunks, similar to extracting individual words from sentences. However, tokenization does not necessarily return a list of words as it aims to deconstruct texts in a way that facilitates the embedding computations. From the result of <a href="#lst-token" class="quarto-xref">Listing&nbsp;3</a>, we see that <code>BertTokenizer</code> generates 33 tokens from the input text and the character or word each token represents.</p>
<div id="23762785" class="cell" data-execution_count="5">
<div id="lst-token" class="python cell-code listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-token-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;3: This code shows how BERT tokenization works.
</figcaption>
<div aria-describedby="lst-token-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode cell-code" id="lst-token"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst-token-1"><a href="#lst-token-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BertTokenizer, BertModel</span>
<span id="lst-token-2"><a href="#lst-token-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="lst-token-3"><a href="#lst-token-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-token-4"><a href="#lst-token-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load pre-trained BERT tokenizer</span></span>
<span id="lst-token-5"><a href="#lst-token-5" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> BertTokenizer.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span>
<span id="lst-token-6"><a href="#lst-token-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-token-7"><a href="#lst-token-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Generated by ChatGPT</span></span>
<span id="lst-token-8"><a href="#lst-token-8" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Artificial intelligence is revolutionizing industries, making processes faster and more efficient. Despite its rapid advancements, human creativity and empathy remain irreplaceable."</span></span>
<span id="lst-token-9"><a href="#lst-token-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-token-10"><a href="#lst-token-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize the input text</span></span>
<span id="lst-token-11"><a href="#lst-token-11" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tokenizer(text, return_tensors<span class="op">=</span><span class="st">'pt'</span>, truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="lst-token-12"><a href="#lst-token-12" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> inputs[<span class="st">'input_ids'</span>][<span class="dv">0</span>]</span>
<span id="lst-token-13"><a href="#lst-token-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-token-14"><a href="#lst-token-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenization results</span></span>
<span id="lst-token-15"><a href="#lst-token-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of tokens generated: </span><span class="sc">{</span>tokens<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="lst-token-16"><a href="#lst-token-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokenizer.convert_ids_to_tokens(tokens.numpy()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of tokens generated: 33
['[CLS]', 'artificial', 'intelligence', 'is', 'revolution', '##izing', 'industries', ',', 'making', 'processes', 'faster', 'and', 'more', 'efficient', '.', 'despite', 'its', 'rapid', 'advancement', '##s', ',', 'human', 'creativity', 'and', 'empathy', 'remain', 'ir', '##re', '##pl', '##ace', '##able', '.', '[SEP]']</code></pre>
</div>
</div>
<p>In <a href="#lst-bert" class="quarto-xref">Listing&nbsp;4</a>, we input the tokens into the pre-trained <code>BertModel</code> and return the BERT embedding for the token ‘artificial’. The resulting BERT embedding for ‘artificial’ is a 768-dimensional vector.</p>
<div id="fa6639b0" class="cell" data-execution_count="6">
<div id="lst-bert" class="python cell-code listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-bert-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;4: This code shows how we compute BERT embeddings.
</figcaption>
<div aria-describedby="lst-bert-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode cell-code" id="lst-bert"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst-bert-1"><a href="#lst-bert-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load pre-trained BERT model</span></span>
<span id="lst-bert-2"><a href="#lst-bert-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BertModel.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span>
<span id="lst-bert-3"><a href="#lst-bert-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-bert-4"><a href="#lst-bert-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the embeddings from the BERT model</span></span>
<span id="lst-bert-5"><a href="#lst-bert-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="lst-bert-6"><a href="#lst-bert-6" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="lst-bert-7"><a href="#lst-bert-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-bert-8"><a href="#lst-bert-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract embeddings</span></span>
<span id="lst-bert-9"><a href="#lst-bert-9" aria-hidden="true" tabindex="-1"></a>token_embeddings <span class="op">=</span> outputs.last_hidden_state[<span class="dv">0</span>]</span>
<span id="lst-bert-10"><a href="#lst-bert-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-bert-11"><a href="#lst-bert-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Token embeddings shape: (number of tokens in input, embedding dimension)</span></span>
<span id="lst-bert-12"><a href="#lst-bert-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Token: </span><span class="sc">{</span>tokenizer<span class="sc">.</span>convert_ids_to_tokens(tokens.numpy())[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="lst-bert-13"><a href="#lst-bert-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Embedding shape: </span><span class="sc">{</span>token_embeddings[<span class="dv">1</span>]<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="lst-bert-14"><a href="#lst-bert-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First 10 values in the embedding: </span><span class="sc">{</span>token_embeddings[<span class="dv">1</span>][:<span class="dv">10</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Token: artificial
Embedding shape: torch.Size([768])
First 10 values in the embedding: tensor([ 0.1357,  0.3550, -0.1805,  0.1837,  0.5278,  0.0016,  0.1048,  0.4054,
         0.2871, -0.8610])</code></pre>
</div>
</div>
<p>If you have followed the demonstration above, you might have noticed the significant time and size the pre-trained model takes when initially loaded. The heavy computational cost is a noticeable drawback of BERT. If you aim to train an NLP model on simple textual data while preserving efficiency, the previously introduced models will be a better choice to encode the data.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Encoding text into numbers is a foundational step in NLP. The choice of encoding method, whether it is simple approaches like Bag of Words or advanced contextual embeddings like BERT, significantly impacts the performance and outcomes of NLP tasks. Each method has its strengths and limitations. Thus, the selection process of text encoders is crucial to achieving the desired results.</p>
<p>The methods introduced in this blog are just the tip of the iceberg. As the field of NLP continues to evolve, discoveries and advancements in NLP are inevitable. Thus, I encourage you to experiment with different encoding techniques and enrich your NLP experience. Whether you are building a sentiment analysis tool, a recommendation system, or a machine translation model, exploring and adapting encoding strategies to suit your project’s unique requirements is key to success. By understanding the power of numerical representations, you can unlock the full potential of NLP and create solutions that bridge the gap between human language and machine understanding.</p>
</section>
<section id="references" class="level2">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" role="list">
<div id="ref-van1995python" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Van Rossum G, Drake Jr FL (1995) Python reference manual. Centrum voor Wiskunde en Informatica Amsterdam</div>
</div>
<div id="ref-scikit-learn" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Pedregosa F, Varoquaux G, Gramfort A, et al (2011) Scikit-learn: Machine learning in <span>P</span>ython. Journal of Machine Learning Research 12:2825–2830</div>
</div>
<div id="ref-mikolov2013efficient" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Mikolov T (2013) Efficient estimation of word representations in vector space. arXiv preprint arXiv:13013781 3781</div>
</div>
<div id="ref-rehurek2011gensim" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Rehurek R, Sojka P (2011) Gensim–python framework for vector space modelling. NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic 3(2)</div>
</div>
<div id="ref-devlin2019bertpretrainingdeepbidirectional" class="csl-entry" role="listitem">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Devlin J, Chang M-W, Lee K, Toutanova K (2019) <a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of deep bidirectional transformers for language understanding</a></div>
</div>
<div id="ref-Devlin_Chang_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Devlin J, Chang M-W (2018) <a href="https://research.google/blog/open-sourcing-bert-state-of-the-art-pre-training-for-natural-language-processing/">Open sourcing BERT: State-of-the-art pre-training for natural language processing</a>. Google Research</div>
</div>
<div id="ref-vaswani2017attention" class="csl-entry" role="listitem">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Vaswani A (2017) Attention is all you need. Advances in Neural Information Processing Systems</div>
</div>
<div id="ref-Hoque_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Hoque M (2024) <a href="https://medium.com/@minh.hoque/a-comprehensive-overview-of-transformer-based-models-encoders-decoders-and-more-e9bc0644a4e5">A comprehensive overview of transformer-based models: Encoders, decoders, and more</a>. Medium</div>
</div>
<div id="ref-wolf2020huggingfacestransformersstateoftheartnatural" class="csl-entry" role="listitem">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Wolf T, Debut L, Sanh V, et al (2020) <a href="https://arxiv.org/abs/1910.03771">HuggingFace’s transformers: State-of-the-art natural language processing</a></div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>